{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset used in breast-cancer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/Srivishnu/OneDrive/Desktop/Project_Code/Cancer_Prediction_using_GenAI/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['diagnosis']).values\n",
    "y = data['diagnosis'].values\n",
    "\n",
    "# Normalize features to range [0, 1]\n",
    "X_normalized = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# Define the size of the latent space\n",
    "latent_dim = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(X_normalized.shape[1], activation='tanh'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Use the learning_rate parameter instead of lr\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    # Use the learning_rate parameter instead of lr\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic real data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    idx = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[idx]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Fake data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan_model, dataset, latent_dim, n_epochs=500, n_batch=128):\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(len(dataset) // n_batch):\n",
    "            X_real, y_real = generate_real_samples(dataset, n_batch)\n",
    "            d_loss_real, _ = discriminator.train_on_batch(X_real, y_real)\n",
    "            X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_batch)\n",
    "            d_loss_fake, _ = discriminator.train_on_batch(X_fake, y_fake)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch+1}/{len(dataset)//n_batch}, D_real_loss={d_loss_real}, D_fake_loss={d_loss_fake}, G_loss={g_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step \n",
      "Epoch 1/500, Batch 1/4, D_real_loss=0.6937148571014404, D_fake_loss=0.6768863201141357, G_loss=0.7301642894744873\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000193DBA5F060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000193DBAD9080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/500, Batch 2/4, D_real_loss=0.6824944615364075, D_fake_loss=0.6761504411697388, G_loss=0.7238840460777283\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 1/500, Batch 3/4, D_real_loss=0.67962247133255, D_fake_loss=0.6794012188911438, G_loss=0.7234789729118347\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/500, Batch 4/4, D_real_loss=0.6814503073692322, D_fake_loss=0.6811589002609253, G_loss=0.7228841185569763\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 2/500, Batch 1/4, D_real_loss=0.6826294660568237, D_fake_loss=0.6826175451278687, G_loss=0.7223008871078491\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 2/500, Batch 2/4, D_real_loss=0.6836557984352112, D_fake_loss=0.6850094199180603, G_loss=0.7169143557548523\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 2/500, Batch 3/4, D_real_loss=0.6857265830039978, D_fake_loss=0.6868306398391724, G_loss=0.7129042744636536\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 2/500, Batch 4/4, D_real_loss=0.6872755289077759, D_fake_loss=0.6885330080986023, G_loss=0.7091750502586365\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 3/500, Batch 1/4, D_real_loss=0.6888564825057983, D_fake_loss=0.6911414265632629, G_loss=0.7064635753631592\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 3/500, Batch 2/4, D_real_loss=0.6912992000579834, D_fake_loss=0.6929060220718384, G_loss=0.7039704322814941\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 3/500, Batch 3/4, D_real_loss=0.6929585337638855, D_fake_loss=0.6951708197593689, G_loss=0.700312077999115\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 3/500, Batch 4/4, D_real_loss=0.695106029510498, D_fake_loss=0.6975457668304443, G_loss=0.6959313750267029\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "Epoch 4/500, Batch 1/4, D_real_loss=0.6974043250083923, D_fake_loss=0.7000114917755127, G_loss=0.6920760273933411\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 4/500, Batch 2/4, D_real_loss=0.6998019814491272, D_fake_loss=0.7020564079284668, G_loss=0.6886546015739441\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 4/500, Batch 3/4, D_real_loss=0.7017887830734253, D_fake_loss=0.7041584849357605, G_loss=0.6847782135009766\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 4/500, Batch 4/4, D_real_loss=0.7038289308547974, D_fake_loss=0.7059714198112488, G_loss=0.6817336082458496\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 5/500, Batch 1/4, D_real_loss=0.7056100368499756, D_fake_loss=0.707787275314331, G_loss=0.677668571472168\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Epoch 5/500, Batch 2/4, D_real_loss=0.7073872089385986, D_fake_loss=0.7095229029655457, G_loss=0.6741758584976196\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 5/500, Batch 3/4, D_real_loss=0.7090933322906494, D_fake_loss=0.7112646102905273, G_loss=0.671156108379364\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "Epoch 5/500, Batch 4/4, D_real_loss=0.7108100652694702, D_fake_loss=0.7132582068443298, G_loss=0.6677681803703308\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 6/500, Batch 1/4, D_real_loss=0.7127843499183655, D_fake_loss=0.7147032618522644, G_loss=0.6647631525993347\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 6/500, Batch 2/4, D_real_loss=0.7142208218574524, D_fake_loss=0.7166891694068909, G_loss=0.6614485383033752\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 6/500, Batch 3/4, D_real_loss=0.7161914110183716, D_fake_loss=0.7183769941329956, G_loss=0.6586857438087463\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 6/500, Batch 4/4, D_real_loss=0.7178582549095154, D_fake_loss=0.7201983332633972, G_loss=0.6552810668945312\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 7/500, Batch 1/4, D_real_loss=0.7196685075759888, D_fake_loss=0.7220689654350281, G_loss=0.6518877148628235\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 7/500, Batch 2/4, D_real_loss=0.7215121388435364, D_fake_loss=0.7238285541534424, G_loss=0.6490983963012695\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 7/500, Batch 3/4, D_real_loss=0.7232658267021179, D_fake_loss=0.7259040474891663, G_loss=0.6456685066223145\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 7/500, Batch 4/4, D_real_loss=0.7253220081329346, D_fake_loss=0.7275299429893494, G_loss=0.6424588561058044\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 8/500, Batch 1/4, D_real_loss=0.7269434332847595, D_fake_loss=0.7292059659957886, G_loss=0.639229953289032\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 8/500, Batch 2/4, D_real_loss=0.728611171245575, D_fake_loss=0.7309682965278625, G_loss=0.6361737847328186\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 8/500, Batch 3/4, D_real_loss=0.7303573489189148, D_fake_loss=0.7330407500267029, G_loss=0.6334302425384521\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step\n",
      "Epoch 8/500, Batch 4/4, D_real_loss=0.7324227690696716, D_fake_loss=0.7349256277084351, G_loss=0.6303272843360901\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 9/500, Batch 1/4, D_real_loss=0.7342947125434875, D_fake_loss=0.7370070219039917, G_loss=0.6276295781135559\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 9/500, Batch 2/4, D_real_loss=0.736368715763092, D_fake_loss=0.7387745380401611, G_loss=0.6247477531433105\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 9/500, Batch 3/4, D_real_loss=0.7381308674812317, D_fake_loss=0.7406010031700134, G_loss=0.6214516162872314\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 9/500, Batch 4/4, D_real_loss=0.7399449944496155, D_fake_loss=0.7423774003982544, G_loss=0.6185745000839233\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 10/500, Batch 1/4, D_real_loss=0.7417134046554565, D_fake_loss=0.7442113757133484, G_loss=0.6157909035682678\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 10/500, Batch 2/4, D_real_loss=0.7435526251792908, D_fake_loss=0.7462723851203918, G_loss=0.6127883791923523\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 10/500, Batch 3/4, D_real_loss=0.7455890774726868, D_fake_loss=0.7481434345245361, G_loss=0.6099780797958374\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 10/500, Batch 4/4, D_real_loss=0.7474673986434937, D_fake_loss=0.750027596950531, G_loss=0.6071699857711792\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 11/500, Batch 1/4, D_real_loss=0.7493414282798767, D_fake_loss=0.7521076202392578, G_loss=0.6042118072509766\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n",
      "Epoch 11/500, Batch 2/4, D_real_loss=0.7514089345932007, D_fake_loss=0.7538875937461853, G_loss=0.6012479066848755\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 11/500, Batch 3/4, D_real_loss=0.7531859278678894, D_fake_loss=0.7559662461280823, G_loss=0.5983471274375916\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 11/500, Batch 4/4, D_real_loss=0.7552542686462402, D_fake_loss=0.7578235864639282, G_loss=0.595414400100708\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 12/500, Batch 1/4, D_real_loss=0.7571016550064087, D_fake_loss=0.759644627571106, G_loss=0.5925374627113342\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 12/500, Batch 2/4, D_real_loss=0.7589266300201416, D_fake_loss=0.7615802884101868, G_loss=0.5894483327865601\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 12/500, Batch 3/4, D_real_loss=0.7608544826507568, D_fake_loss=0.7636362314224243, G_loss=0.5868038535118103\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 12/500, Batch 4/4, D_real_loss=0.7629001140594482, D_fake_loss=0.7657524943351746, G_loss=0.583885669708252\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 13/500, Batch 1/4, D_real_loss=0.7650149464607239, D_fake_loss=0.7677634954452515, G_loss=0.5809658169746399\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 13/500, Batch 2/4, D_real_loss=0.7670175433158875, D_fake_loss=0.7698895335197449, G_loss=0.578193187713623\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 13/500, Batch 3/4, D_real_loss=0.7691356539726257, D_fake_loss=0.771744966506958, G_loss=0.575268030166626\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Epoch 13/500, Batch 4/4, D_real_loss=0.7709868550300598, D_fake_loss=0.7736354470252991, G_loss=0.5725303292274475\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 14/500, Batch 1/4, D_real_loss=0.7728725671768188, D_fake_loss=0.7754746675491333, G_loss=0.5697908401489258\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "Epoch 14/500, Batch 2/4, D_real_loss=0.7747138142585754, D_fake_loss=0.7776467800140381, G_loss=0.5671209096908569\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 14/500, Batch 3/4, D_real_loss=0.7768771052360535, D_fake_loss=0.7796284556388855, G_loss=0.5641536116600037\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 14/500, Batch 4/4, D_real_loss=0.7788572311401367, D_fake_loss=0.7815574407577515, G_loss=0.5614959001541138\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 15/500, Batch 1/4, D_real_loss=0.7807799577713013, D_fake_loss=0.783557116985321, G_loss=0.558804988861084\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 15/500, Batch 2/4, D_real_loss=0.7827777862548828, D_fake_loss=0.7856827974319458, G_loss=0.5561410784721375\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 15/500, Batch 3/4, D_real_loss=0.7848946452140808, D_fake_loss=0.7876696586608887, G_loss=0.553712010383606\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 15/500, Batch 4/4, D_real_loss=0.7868821620941162, D_fake_loss=0.7896167635917664, G_loss=0.5512356162071228\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 16/500, Batch 1/4, D_real_loss=0.7888236045837402, D_fake_loss=0.791832685470581, G_loss=0.5485967397689819\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 16/500, Batch 2/4, D_real_loss=0.7910372018814087, D_fake_loss=0.7938555479049683, G_loss=0.5457907319068909\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 16/500, Batch 3/4, D_real_loss=0.7930598258972168, D_fake_loss=0.7960517406463623, G_loss=0.5431874990463257\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 16/500, Batch 4/4, D_real_loss=0.7952494025230408, D_fake_loss=0.798040509223938, G_loss=0.5407559275627136\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 17/500, Batch 1/4, D_real_loss=0.7972297668457031, D_fake_loss=0.800220787525177, G_loss=0.5383065938949585\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 17/500, Batch 2/4, D_real_loss=0.7994096875190735, D_fake_loss=0.8022376894950867, G_loss=0.5357691049575806\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 17/500, Batch 3/4, D_real_loss=0.8014214634895325, D_fake_loss=0.804259181022644, G_loss=0.5333651900291443\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 17/500, Batch 4/4, D_real_loss=0.803442656993866, D_fake_loss=0.8062774538993835, G_loss=0.530896008014679\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 18/500, Batch 1/4, D_real_loss=0.8054566383361816, D_fake_loss=0.8084319233894348, G_loss=0.5283815860748291\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107us/step\n",
      "Epoch 18/500, Batch 2/4, D_real_loss=0.8076104521751404, D_fake_loss=0.8105605244636536, G_loss=0.5259178876876831\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 18/500, Batch 3/4, D_real_loss=0.8097370862960815, D_fake_loss=0.8125865459442139, G_loss=0.5235055088996887\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 18/500, Batch 4/4, D_real_loss=0.8117607235908508, D_fake_loss=0.8146283626556396, G_loss=0.5210205316543579\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 19/500, Batch 1/4, D_real_loss=0.8137936592102051, D_fake_loss=0.8166971802711487, G_loss=0.5185838937759399\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 19/500, Batch 2/4, D_real_loss=0.8158626556396484, D_fake_loss=0.818716824054718, G_loss=0.5162057876586914\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 19/500, Batch 3/4, D_real_loss=0.8178805112838745, D_fake_loss=0.8207173347473145, G_loss=0.5140208601951599\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 19/500, Batch 4/4, D_real_loss=0.8198867440223694, D_fake_loss=0.8227942585945129, G_loss=0.5116661787033081\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 20/500, Batch 1/4, D_real_loss=0.8219516277313232, D_fake_loss=0.8249019384384155, G_loss=0.5093762874603271\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 20/500, Batch 2/4, D_real_loss=0.8240563869476318, D_fake_loss=0.827034592628479, G_loss=0.5070984959602356\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 20/500, Batch 3/4, D_real_loss=0.8261834383010864, D_fake_loss=0.8291653990745544, G_loss=0.5048484802246094\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 20/500, Batch 4/4, D_real_loss=0.8283156752586365, D_fake_loss=0.8313800692558289, G_loss=0.5024669766426086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 21/500, Batch 1/4, D_real_loss=0.8305251002311707, D_fake_loss=0.8333702683448792, G_loss=0.5002096891403198\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 21/500, Batch 2/4, D_real_loss=0.8325181007385254, D_fake_loss=0.8354403972625732, G_loss=0.4979563057422638\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 21/500, Batch 3/4, D_real_loss=0.8345806002616882, D_fake_loss=0.8377007246017456, G_loss=0.4958067238330841\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Epoch 21/500, Batch 4/4, D_real_loss=0.8368440866470337, D_fake_loss=0.8398464918136597, G_loss=0.49362972378730774\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 22/500, Batch 1/4, D_real_loss=0.8389841318130493, D_fake_loss=0.841942548751831, G_loss=0.4914649426937103\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 22/500, Batch 2/4, D_real_loss=0.8410777449607849, D_fake_loss=0.843995213508606, G_loss=0.4892469346523285\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 22/500, Batch 3/4, D_real_loss=0.8431307673454285, D_fake_loss=0.8459543585777283, G_loss=0.48712360858917236\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step\n",
      "Epoch 22/500, Batch 4/4, D_real_loss=0.8450869917869568, D_fake_loss=0.8479874134063721, G_loss=0.48502835631370544\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 23/500, Batch 1/4, D_real_loss=0.8471143245697021, D_fake_loss=0.8500096797943115, G_loss=0.4829311668872833\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 23/500, Batch 2/4, D_real_loss=0.8491424322128296, D_fake_loss=0.8520615696907043, G_loss=0.4808512330055237\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 23/500, Batch 3/4, D_real_loss=0.8511885404586792, D_fake_loss=0.8541032671928406, G_loss=0.4787602722644806\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Epoch 23/500, Batch 4/4, D_real_loss=0.8532284498214722, D_fake_loss=0.8561456203460693, G_loss=0.47677910327911377\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "Epoch 24/500, Batch 1/4, D_real_loss=0.8552685976028442, D_fake_loss=0.8581021428108215, G_loss=0.4747451841831207\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 24/500, Batch 2/4, D_real_loss=0.8572276830673218, D_fake_loss=0.8600733280181885, G_loss=0.47272607684135437\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 24/500, Batch 3/4, D_real_loss=0.8591930866241455, D_fake_loss=0.8620679974555969, G_loss=0.47070378065109253\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 24/500, Batch 4/4, D_real_loss=0.861186146736145, D_fake_loss=0.864018976688385, G_loss=0.4687717854976654\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step\n",
      "Epoch 25/500, Batch 1/4, D_real_loss=0.8631401062011719, D_fake_loss=0.8660503029823303, G_loss=0.4668484032154083\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 25/500, Batch 2/4, D_real_loss=0.8651683926582336, D_fake_loss=0.8681201338768005, G_loss=0.46491143107414246\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 25/500, Batch 3/4, D_real_loss=0.8672336339950562, D_fake_loss=0.8700559735298157, G_loss=0.4629995822906494\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 25/500, Batch 4/4, D_real_loss=0.8691704273223877, D_fake_loss=0.8719562292098999, G_loss=0.46110308170318604\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "Epoch 26/500, Batch 1/4, D_real_loss=0.8710715174674988, D_fake_loss=0.8739998936653137, G_loss=0.45918262004852295\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 26/500, Batch 2/4, D_real_loss=0.873115062713623, D_fake_loss=0.8760175704956055, G_loss=0.45734670758247375\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 26/500, Batch 3/4, D_real_loss=0.8751319646835327, D_fake_loss=0.877946138381958, G_loss=0.45552000403404236\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 26/500, Batch 4/4, D_real_loss=0.8770583868026733, D_fake_loss=0.8797648549079895, G_loss=0.4536938965320587\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 27/500, Batch 1/4, D_real_loss=0.8788760304450989, D_fake_loss=0.8816518187522888, G_loss=0.45183849334716797\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 27/500, Batch 2/4, D_real_loss=0.880761444568634, D_fake_loss=0.8836660385131836, G_loss=0.45001736283302307\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 27/500, Batch 3/4, D_real_loss=0.8827749490737915, D_fake_loss=0.8856247663497925, G_loss=0.4482021927833557\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 27/500, Batch 4/4, D_real_loss=0.8847338557243347, D_fake_loss=0.8875739574432373, G_loss=0.44641268253326416\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 28/500, Batch 1/4, D_real_loss=0.8866819143295288, D_fake_loss=0.8894411325454712, G_loss=0.4446316957473755\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 28/500, Batch 2/4, D_real_loss=0.8885495066642761, D_fake_loss=0.8913179636001587, G_loss=0.4428611099720001\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 28/500, Batch 3/4, D_real_loss=0.8904261589050293, D_fake_loss=0.8932026624679565, G_loss=0.4410974681377411\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 28/500, Batch 4/4, D_real_loss=0.8923073410987854, D_fake_loss=0.8951491713523865, G_loss=0.43938693404197693\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 29/500, Batch 1/4, D_real_loss=0.894256055355072, D_fake_loss=0.8970469236373901, G_loss=0.4377242624759674\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 29/500, Batch 2/4, D_real_loss=0.8961564302444458, D_fake_loss=0.898913562297821, G_loss=0.43604981899261475\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 29/500, Batch 3/4, D_real_loss=0.8980203866958618, D_fake_loss=0.9007783532142639, G_loss=0.4344370365142822\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 29/500, Batch 4/4, D_real_loss=0.8998827338218689, D_fake_loss=0.9025967717170715, G_loss=0.43278515338897705\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 30/500, Batch 1/4, D_real_loss=0.9017024636268616, D_fake_loss=0.9044822454452515, G_loss=0.431139200925827\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 30/500, Batch 2/4, D_real_loss=0.9035850167274475, D_fake_loss=0.9062770009040833, G_loss=0.42949551343917847\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 30/500, Batch 3/4, D_real_loss=0.9053852558135986, D_fake_loss=0.9081205129623413, G_loss=0.4279090166091919\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 30/500, Batch 4/4, D_real_loss=0.9072287082672119, D_fake_loss=0.9099640250205994, G_loss=0.42633965611457825\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 31/500, Batch 1/4, D_real_loss=0.9090680480003357, D_fake_loss=0.9117987751960754, G_loss=0.42475083470344543\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 31/500, Batch 2/4, D_real_loss=0.9109018445014954, D_fake_loss=0.913624107837677, G_loss=0.42317020893096924\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 31/500, Batch 3/4, D_real_loss=0.9127283096313477, D_fake_loss=0.9155346751213074, G_loss=0.42162206768989563\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 31/500, Batch 4/4, D_real_loss=0.9146372675895691, D_fake_loss=0.9173471331596375, G_loss=0.4200873076915741\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 32/500, Batch 1/4, D_real_loss=0.9164517521858215, D_fake_loss=0.9191135168075562, G_loss=0.4185415208339691\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43us/step\n",
      "Epoch 32/500, Batch 2/4, D_real_loss=0.9182184338569641, D_fake_loss=0.9208338856697083, G_loss=0.4170553684234619\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 32/500, Batch 3/4, D_real_loss=0.9199361801147461, D_fake_loss=0.9225817322731018, G_loss=0.41556811332702637\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 32/500, Batch 4/4, D_real_loss=0.9216881990432739, D_fake_loss=0.9243618845939636, G_loss=0.4140964448451996\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step\n",
      "Epoch 33/500, Batch 1/4, D_real_loss=0.9234651923179626, D_fake_loss=0.9261300563812256, G_loss=0.4126480519771576\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 33/500, Batch 2/4, D_real_loss=0.9252338409423828, D_fake_loss=0.9278382062911987, G_loss=0.41119736433029175\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 33/500, Batch 3/4, D_real_loss=0.9269425868988037, D_fake_loss=0.9295559525489807, G_loss=0.409746378660202\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 33/500, Batch 4/4, D_real_loss=0.9286594390869141, D_fake_loss=0.9312416911125183, G_loss=0.4083450138568878\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 34/500, Batch 1/4, D_real_loss=0.9303461909294128, D_fake_loss=0.9329392910003662, G_loss=0.4069902002811432\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 34/500, Batch 2/4, D_real_loss=0.9320451617240906, D_fake_loss=0.9346345067024231, G_loss=0.40559229254722595\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 34/500, Batch 3/4, D_real_loss=0.9337406754493713, D_fake_loss=0.9362961053848267, G_loss=0.40420809388160706\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 34/500, Batch 4/4, D_real_loss=0.9354054927825928, D_fake_loss=0.9379652142524719, G_loss=0.4028216302394867\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 35/500, Batch 1/4, D_real_loss=0.9370707273483276, D_fake_loss=0.9396808743476868, G_loss=0.4014556109905243\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 35/500, Batch 2/4, D_real_loss=0.9387874007225037, D_fake_loss=0.9413502812385559, G_loss=0.40010371804237366\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 35/500, Batch 3/4, D_real_loss=0.9404588937759399, D_fake_loss=0.9430109262466431, G_loss=0.39880287647247314\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 35/500, Batch 4/4, D_real_loss=0.9421206116676331, D_fake_loss=0.9446717500686646, G_loss=0.39745888113975525\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 36/500, Batch 1/4, D_real_loss=0.9437797665596008, D_fake_loss=0.9462870359420776, G_loss=0.3961622416973114\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 36/500, Batch 2/4, D_real_loss=0.9453963041305542, D_fake_loss=0.9479113221168518, G_loss=0.39485013484954834\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 36/500, Batch 3/4, D_real_loss=0.9470202922821045, D_fake_loss=0.9495580792427063, G_loss=0.3935524523258209\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 36/500, Batch 4/4, D_real_loss=0.948668360710144, D_fake_loss=0.9511488676071167, G_loss=0.39228105545043945\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 37/500, Batch 1/4, D_real_loss=0.9502601623535156, D_fake_loss=0.9527475237846375, G_loss=0.39101648330688477\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 37/500, Batch 2/4, D_real_loss=0.95185786485672, D_fake_loss=0.954340398311615, G_loss=0.389745831489563\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 37/500, Batch 3/4, D_real_loss=0.9534515142440796, D_fake_loss=0.9559264779090881, G_loss=0.3885118067264557\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 37/500, Batch 4/4, D_real_loss=0.9550393223762512, D_fake_loss=0.9574810862541199, G_loss=0.3872910439968109\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 38/500, Batch 1/4, D_real_loss=0.9565936326980591, D_fake_loss=0.9590997695922852, G_loss=0.3860700726509094\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 38/500, Batch 2/4, D_real_loss=0.9582116603851318, D_fake_loss=0.9606444239616394, G_loss=0.3848501443862915\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 38/500, Batch 3/4, D_real_loss=0.9597593545913696, D_fake_loss=0.9622313380241394, G_loss=0.38365986943244934\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 38/500, Batch 4/4, D_real_loss=0.9613460302352905, D_fake_loss=0.9637957215309143, G_loss=0.38246145844459534\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 39/500, Batch 1/4, D_real_loss=0.9629104137420654, D_fake_loss=0.9653564691543579, G_loss=0.3812917470932007\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 39/500, Batch 2/4, D_real_loss=0.9644725918769836, D_fake_loss=0.9668351411819458, G_loss=0.3801268935203552\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 39/500, Batch 3/4, D_real_loss=0.9659539461135864, D_fake_loss=0.9683809280395508, G_loss=0.37897181510925293\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 39/500, Batch 4/4, D_real_loss=0.9674984812736511, D_fake_loss=0.9699109196662903, G_loss=0.3778320550918579\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 40/500, Batch 1/4, D_real_loss=0.9690293669700623, D_fake_loss=0.971389651298523, G_loss=0.37669655680656433\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 40/500, Batch 2/4, D_real_loss=0.9705085754394531, D_fake_loss=0.9729499220848083, G_loss=0.37555184960365295\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 40/500, Batch 3/4, D_real_loss=0.97207111120224, D_fake_loss=0.9744032621383667, G_loss=0.3744136691093445\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 40/500, Batch 4/4, D_real_loss=0.9735242128372192, D_fake_loss=0.9758697748184204, G_loss=0.37330058217048645\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 41/500, Batch 1/4, D_real_loss=0.9749909043312073, D_fake_loss=0.9773029685020447, G_loss=0.3721998929977417\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 41/500, Batch 2/4, D_real_loss=0.9764275550842285, D_fake_loss=0.9787558317184448, G_loss=0.37110820412635803\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 41/500, Batch 3/4, D_real_loss=0.9778797030448914, D_fake_loss=0.9801852703094482, G_loss=0.37002843618392944\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 41/500, Batch 4/4, D_real_loss=0.9793118834495544, D_fake_loss=0.9816343784332275, G_loss=0.3689689338207245\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 42/500, Batch 1/4, D_real_loss=0.980760931968689, D_fake_loss=0.9830924272537231, G_loss=0.3679027557373047\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 42/500, Batch 2/4, D_real_loss=0.9822183847427368, D_fake_loss=0.9844834804534912, G_loss=0.3668445944786072\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 42/500, Batch 3/4, D_real_loss=0.9836105704307556, D_fake_loss=0.9858922958374023, G_loss=0.36580437421798706\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 42/500, Batch 4/4, D_real_loss=0.9850212335586548, D_fake_loss=0.9872989654541016, G_loss=0.3647720217704773\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 43/500, Batch 1/4, D_real_loss=0.986430823802948, D_fake_loss=0.9887111186981201, G_loss=0.3637480139732361\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 43/500, Batch 2/4, D_real_loss=0.9878413081169128, D_fake_loss=0.9901098608970642, G_loss=0.3627207279205322\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 43/500, Batch 3/4, D_real_loss=0.989241361618042, D_fake_loss=0.9914731979370117, G_loss=0.36170494556427\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 43/500, Batch 4/4, D_real_loss=0.9906046986579895, D_fake_loss=0.9928690195083618, G_loss=0.360702782869339\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 44/500, Batch 1/4, D_real_loss=0.992003321647644, D_fake_loss=0.9942307472229004, G_loss=0.3597189486026764\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 44/500, Batch 2/4, D_real_loss=0.9933645725250244, D_fake_loss=0.995587944984436, G_loss=0.35873204469680786\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 44/500, Batch 3/4, D_real_loss=0.9947234988212585, D_fake_loss=0.996948778629303, G_loss=0.35775092244148254\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 44/500, Batch 4/4, D_real_loss=0.996084451675415, D_fake_loss=0.9982994198799133, G_loss=0.3567701578140259\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 45/500, Batch 1/4, D_real_loss=0.9974374175071716, D_fake_loss=0.9996331930160522, G_loss=0.35580846667289734\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 45/500, Batch 2/4, D_real_loss=0.9987709522247314, D_fake_loss=1.0009243488311768, G_loss=0.35484787821769714\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 45/500, Batch 3/4, D_real_loss=1.0000650882720947, D_fake_loss=1.002235770225525, G_loss=0.3539046347141266\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 45/500, Batch 4/4, D_real_loss=1.0013762712478638, D_fake_loss=1.0035560131072998, G_loss=0.3529711365699768\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 46/500, Batch 1/4, D_real_loss=1.0026979446411133, D_fake_loss=1.004859447479248, G_loss=0.3520503044128418\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 46/500, Batch 2/4, D_real_loss=1.0040017366409302, D_fake_loss=1.0061372518539429, G_loss=0.3511262536048889\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 46/500, Batch 3/4, D_real_loss=1.0052835941314697, D_fake_loss=1.0074511766433716, G_loss=0.3502189815044403\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 46/500, Batch 4/4, D_real_loss=1.0065969228744507, D_fake_loss=1.0087603330612183, G_loss=0.34929338097572327\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 47/500, Batch 1/4, D_real_loss=1.0079082250595093, D_fake_loss=1.0100598335266113, G_loss=0.348394513130188\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Epoch 47/500, Batch 2/4, D_real_loss=1.0092086791992188, D_fake_loss=1.0113213062286377, G_loss=0.34750017523765564\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 47/500, Batch 3/4, D_real_loss=1.0104707479476929, D_fake_loss=1.0126030445098877, G_loss=0.3466155230998993\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 47/500, Batch 4/4, D_real_loss=1.0117532014846802, D_fake_loss=1.0138713121414185, G_loss=0.345720499753952\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 48/500, Batch 1/4, D_real_loss=1.0130221843719482, D_fake_loss=1.0151017904281616, G_loss=0.34484726190567017\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 48/500, Batch 2/4, D_real_loss=1.0142539739608765, D_fake_loss=1.0163545608520508, G_loss=0.34397968649864197\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 48/500, Batch 3/4, D_real_loss=1.015508770942688, D_fake_loss=1.0175975561141968, G_loss=0.34310686588287354\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 48/500, Batch 4/4, D_real_loss=1.0167533159255981, D_fake_loss=1.018818736076355, G_loss=0.3422468900680542\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 49/500, Batch 1/4, D_real_loss=1.0179743766784668, D_fake_loss=1.020052194595337, G_loss=0.34139373898506165\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 49/500, Batch 2/4, D_real_loss=1.0192099809646606, D_fake_loss=1.0213062763214111, G_loss=0.3405531942844391\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "Epoch 49/500, Batch 3/4, D_real_loss=1.020464301109314, D_fake_loss=1.0225393772125244, G_loss=0.3397080600261688\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 49/500, Batch 4/4, D_real_loss=1.0216994285583496, D_fake_loss=1.023765206336975, G_loss=0.33887186646461487\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 50/500, Batch 1/4, D_real_loss=1.0229262113571167, D_fake_loss=1.0249557495117188, G_loss=0.3380456566810608\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m gan_model \u001b[38;5;241m=\u001b[39m define_gan(generator, discriminator)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Train GAN\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m      8\u001b[0m X_gan \u001b[38;5;241m=\u001b[39m generate_latent_points(latent_dim, n_batch)\n\u001b[0;32m      9\u001b[0m y_gan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((n_batch, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_gan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mn_batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D_real_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss_real\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D_fake_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss_fake\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, G_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:551\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 551\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:118\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 118\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    122\u001b[0m     outputs,\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    124\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:138\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:391\u001b[0m, in \u001b[0;36mFunctionType.unpack_inputs\u001b[1;34m(self, bound_parameters)\u001b[0m\n\u001b[0;32m    388\u001b[0m flat \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sorted_parameters:\n\u001b[0;32m    390\u001b[0m   flat\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 391\u001b[0m       \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m   )\n\u001b[0;32m    394\u001b[0m dealiased_inputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    395\u001b[0m ids_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\default_types.py:260\u001b[0m, in \u001b[0;36mTuple.to_tensors\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    258\u001b[0m flattened_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comp_value, comp_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents):\n\u001b[1;32m--> 260\u001b[0m   flattened_values\u001b[38;5;241m.\u001b[39mextend(\u001b[43mcomp_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp_value\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flattened_values\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:1081\u001b[0m, in \u001b[0;36mTensorSpec.to_tensors\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tensors\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m-> 1081\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInternalCastContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mis_subtype_of(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1084\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived tensor of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1085\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:1108\u001b[0m, in \u001b[0;36mTensorSpec.cast\u001b[1;34m(self, value, casting_context)\u001b[0m\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor):\n\u001b[1;32m-> 1108\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m value_spec \u001b[38;5;241m=\u001b[39m TensorSpec(value\u001b[38;5;241m.\u001b[39mshape, value\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value_spec\u001b[38;5;241m.\u001b[39mis_subtype_of(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[0;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:291\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_broadcast\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:281\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    279\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    280\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[1;32m--> 281\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m    285\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m    286\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m    287\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m    288\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2682\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   2679\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 2682\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2683\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2684\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2686\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2688\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2689\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2691\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2692\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1177\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1177\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Srivishnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1034\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1030\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1031\u001b[0m                                          serialized)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1034\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1036\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define discriminator model\n",
    "discriminator = define_discriminator(X_normalized.shape[1])\n",
    "\n",
    "# Define generator model\n",
    "generator = define_generator(latent_dim)\n",
    "\n",
    "# Define GAN model\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "\n",
    "# Train GAN\n",
    "train_gan(generator, discriminator, gan_model, X_normalized, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic samples using GAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "# Generate synthetic samples using GAN\n",
    "def generate_synthetic_samples(generator, latent_dim, num_samples):\n",
    "    # Generate random noise as input to the generator\n",
    "    latent_points = np.random.randn(num_samples, latent_dim)\n",
    "    # Generate synthetic samples\n",
    "    X_synthetic = generator.predict(latent_points)\n",
    "    return X_synthetic\n",
    "\n",
    "# Number of synthetic samples to generate\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "\n",
    "# Generate synthetic samples\n",
    "X_synthetic = generate_synthetic_samples(generator, latent_dim, num_synthetic_samples)\n",
    "\n",
    "# Combine original and synthetic samples\n",
    "X_augmented = np.vstack((X_normalized, X_synthetic))\n",
    "y_augmented = np.concatenate((y, np.ones(num_synthetic_samples)))  # Assuming all synthetic samples are labeled as 1\n",
    "\n",
    "\n",
    "# Augment dataset with synthetic samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle the augmented dataset\n",
    "X_augmented_shuffled, y_augmented_shuffled = shuffle(X_augmented, y_augmented)\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train_augmented, X_test_augmented, y_train_augmented, y_test_augmented = train_test_split(X_augmented_shuffled, y_augmented_shuffled, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert labels to strings to handle mixed data types\n",
    "y_train_augmented_str = y_train_augmented.astype(str)\n",
    "\n",
    "# Encode labels for training data\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_augmented_str)\n",
    "\n",
    "# Print unique encoded labels for training data\n",
    "print(np.unique(y_train_encoded))\n",
    "\n",
    "# Convert labels to strings for testing data\n",
    "y_test_augmented_str = y_test_augmented.astype(str)\n",
    "\n",
    "# Encode labels for testing data\n",
    "y_test_encoded = label_encoder.transform(y_test_augmented_str)\n",
    "\n",
    "# Print unique encoded labels for testing data\n",
    "print(np.unique(y_test_encoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy on Augmented Testing Dataset: 0.8789808917197452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the SVM classifier on the augmented training dataset\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, gamma='auto')\n",
    "svm_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the classifier on the augmented testing dataset\n",
    "accuracy_augmented = svm_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"SVM Classifier Accuracy on Augmented Testing Dataset:\", accuracy_augmented)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy on Augmented Testing Dataset: 0.9681528662420382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree classifier on the augmented training dataset\n",
    "dt_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the Decision Tree classifier on the augmented testing dataset\n",
    "accuracy_dt = dt_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"Decision Tree Classifier Accuracy on Augmented Testing Dataset:\", accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy on Augmented Testing Dataset: 0.9044585987261147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier on the augmented training dataset\n",
    "rf_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the Random Forest classifier on the augmented testing dataset\n",
    "accuracy_rf = rf_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"Random Forest Classifier Accuracy on Augmented Testing Dataset:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier Accuracy on Augmented Testing Dataset: 0.8789808917197452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the Logistic Regression classifier on the augmented training dataset\n",
    "lr_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the Logistic Regression classifier on the augmented testing dataset\n",
    "accuracy_lr = lr_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"Logistic Regression Classifier Accuracy on Augmented Testing Dataset:\", accuracy_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy on Augmented Testing Dataset: 0.9490445859872612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting classifier on the augmented training dataset\n",
    "gb_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the Gradient Boosting classifier on the augmented testing dataset\n",
    "accuracy_gb = gb_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"Gradient Boosting Classifier Accuracy on Augmented Testing Dataset:\", accuracy_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy on Augmented Testing Dataset: 0.9171974522292994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Train the KNN classifier on the augmented training dataset\n",
    "knn_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the KNN classifier on the augmented testing dataset\n",
    "accuracy_knn = knn_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"KNN Classifier Accuracy on Augmented Testing Dataset:\", accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy on Augmented Testing Dataset: 0.9904458598726115\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Train the XGBoost classifier on the augmented training dataset\n",
    "xgb_classifier.fit(X_train_augmented, y_train_encoded)\n",
    "\n",
    "# Evaluate the XGBoost classifier on the augmented testing dataset\n",
    "accuracy_xgb = xgb_classifier.score(X_test_augmented, y_test_encoded)\n",
    "print(\"XGBoost Classifier Accuracy on Augmented Testing Dataset:\", accuracy_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.8789808917197452\n",
      "Decision Tree: 0.9681528662420382\n",
      "Logistic Regression: 0.8789808917197452\n",
      "Random Forest: 0.9044585987261147\n",
      "KNN: 0.9171974522292994\n",
      "XGBoost: 0.9904458598726115\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store model names and their scores\n",
    "model_scores = {}\n",
    "\n",
    "# Add scores for each model to the dictionary\n",
    "model_scores['SVM'] = accuracy_augmented\n",
    "model_scores['Decision Tree'] = accuracy_dt\n",
    "model_scores['Logistic Regression'] = accuracy_lr\n",
    "model_scores['Random Forest'] = accuracy_rf\n",
    "model_scores['KNN'] = accuracy_knn\n",
    "model_scores['XGBoost'] = accuracy_xgb\n",
    "\n",
    "# Print model scores\n",
    "for model, score in model_scores.items():\n",
    "    print(f\"{model}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model  Accuracy\n",
      "0                         SVM  0.878981\n",
      "1                         KNN  0.917197\n",
      "2                     XGBoost  0.990446\n",
      "3      RandomForestClassifier  0.904459\n",
      "4          LogisticRegression  0.878981\n",
      "5  GradientBoostingClassifier  0.949045\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store model names and their scores\n",
    "model_scores = {\n",
    "    'Model': ['SVM', 'KNN', 'XGBoost','RandomForestClassifier','LogisticRegression','GradientBoostingClassifier'],\n",
    "    'Accuracy': [accuracy_augmented, accuracy_knn, accuracy_xgb,accuracy_rf,accuracy_lr,accuracy_gb]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_model_scores = pd.DataFrame(model_scores)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_model_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>99.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>94.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>91.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>90.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>87.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>87.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Score\n",
       "5                       XgBoost  99.04\n",
       "4  Gradient Boosting Classifier  94.90\n",
       "1                           KNN  91.72\n",
       "3      Random Forest Classifier  90.45\n",
       "0           Logistic Regression  87.90\n",
       "2                           SVM  87.90"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'KNN', 'SVM','Random Forest Classifier', 'Gradient Boosting Classifier', 'XgBoost'],\n",
    "    'Score': [100*round(accuracy_lr,4), 100*round(accuracy_knn,4), 100*round(accuracy_augmented,4), 100*round(accuracy_rf,4), \n",
    "              100*round(accuracy_gb,4), 100*round(accuracy_xgb,4)]\n",
    "})\n",
    "models.sort_values(by = 'Score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_model_scores['Model'], df_model_scores['Accuracy'], color='mediumpurple')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracies')\n",
    "\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
